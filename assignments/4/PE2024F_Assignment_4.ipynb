{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfHX2U6tpTvP"
   },
   "source": [
    "# TA Session Topic 4: RAG (Retrieval Augmented Generation)\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "* Check the structure and codes of RAG\n",
    "* Check the impact of chunking strategy on RAG performance\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "1. **Simple RAG Chain**\n",
    "2. **Indexing**\n",
    "3. **Retrieval and Generation**\n",
    "\n",
    "**Reference Links:**\n",
    "\n",
    "1. **LangChain Vector Stores**: [Link](https://python.langchain.com/docs/concepts/vectorstores/)\n",
    "2. **LangChain Retrievers**: [Link](https://python.langchain.com/docs/concepts/retrievers/)\n",
    "3. **LangChain RAG Tutorial**: [Link](https://python.langchain.com/docs/tutorials/rag/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9o8gGNgEx12"
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YD-GUB6s78er"
   },
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install --quiet --upgrade langchain langchain-community langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxcGCntb_9_2"
   },
   "outputs": [],
   "source": [
    "# Install langchain openai\n",
    "!pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2duN-x-D2tMq"
   },
   "source": [
    "### Set API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3K6uUOvP8DP"
   },
   "outputs": [],
   "source": [
    "# Set API key\n",
    "OPENAI_API_KEY=\"your_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztDA7lWl5Z4s"
   },
   "source": [
    "## Prepare Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Qxvsp02nW5y"
   },
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgXXsDJ-ATFW"
   },
   "source": [
    "## 1. Simple RAG Chain Example\n",
    "\n",
    "We will use a web document as a source for the retrieval.\n",
    "\n",
    "Document source: [link](https://arxiv.org/html/2312.10997v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AK3pLYhDI-fy"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the contents of the paper\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://arxiv.org/html/2312.10997v5\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"ltx_abstract\", \"ltx_section\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Chunk and index the document\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(model='text-embedding-3-small', api_key=OPENAI_API_KEY))\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the paper.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CeZ0eX-geQ9f"
   },
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"What types of RAG exist?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pwi7H5oP_A70"
   },
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Tell me about the various chunking methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uy9jMd4MHv9"
   },
   "outputs": [],
   "source": [
    "# cleanup\n",
    "vectorstore.delete_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YA8GXiIRHh4C"
   },
   "source": [
    "## 2. Indexing\n",
    "\n",
    "*   Load: Load the data with Document Loaders.\n",
    "*   Split: Text splitters break large Documents into smaller chunks. This is useful both for indexing data and for passing it in to a model, since large chunks are harder to search over and won't fit in a model's finite context window.\n",
    "*   Store: Using a VectorStore and Embeddings model, store and index the splits, so that they can later be searched over.\n",
    "\n",
    "![Indexing](https://python.langchain.com/assets/images/rag_indexing-8160f90a90a33253d0154659cf7d453f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZWBH3-VRMLw"
   },
   "source": [
    "We use DocumentLoaders for load documents.\n",
    "\n",
    "https://python.langchain.com/docs/concepts/document_loaders/\n",
    "\n",
    "You can also load [pdf](https://python.langchain.com/docs/how_to/document_loader_pdf/), [csv](https://python.langchain.com/docs/how_to/document_loader_csv/) formatted documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxYor3w8Hv1E"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep abstract, sections from the full HTML.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://arxiv.org/html/2312.10997v5\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"ltx_abstract\", \"ltx_section\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUjObxhsNWPo"
   },
   "outputs": [],
   "source": [
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWXfmptCNksY"
   },
   "source": [
    "We will split our documents into chunks of 1000 characters with 200 characters of overlap between chunks.\n",
    "\n",
    "The overlap helps mitigate the possibility of separating a statement from important context related to it.\n",
    "\n",
    "We use [RecursiveCharacterTextSplitter](https://python.langchain.com/docs/how_to/recursive_text_splitter/), which will recursively split the document using common separators (default: `[\"\\n\\n\", \"\\n\", \" \", \"\"]`) until each chunk is the appropriate size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVECyeeuNZSj"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3de_pLWAHgjq"
   },
   "outputs": [],
   "source": [
    "len(all_splits[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TS6OpzU1S6TU"
   },
   "outputs": [],
   "source": [
    "all_splits[10].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OksMFm9vTd6b"
   },
   "source": [
    "Check [link](https://python.langchain.com/docs/how_to/#text-splitters) for other LangChain splitters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kmTN9kbTn2a"
   },
   "source": [
    "We can embed and store all of our document splits in a single command using the Chroma vector store and OpenAIEmbeddings model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yrH__ClTwgC"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings(model='text-embedding-3-small', api_key=OPENAI_API_KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X59_m1ryT9ok"
   },
   "source": [
    "## Retrieval and Generation\n",
    "\n",
    "*   Retrieve: Given a user input, relevant splits are retrieved from storage using a Retriever.\n",
    "*   Generate: A ChatModel / LLM produces an answer using a prompt that includes the question and the retrieved data\n",
    "\n",
    "![Retrieval and Generation](https://python.langchain.com/assets/images/rag_retrieval_generation-1046a4668d6bb08786ef73c56d4f228a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ylkyQhPUSol"
   },
   "source": [
    "LangChain defines a Retriever interface which wraps an index that can return relevant Documents given a string query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFI4yQ-EUcvz"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"What are the approaches to the query rewriting?\")\n",
    "\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "by28gquSUmqQ"
   },
   "outputs": [],
   "source": [
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OLQMdI6Uv8F"
   },
   "source": [
    "Let’s put it all together into a chain that takes a question, retrieves relevant documents, constructs a prompt, passes that to a model, and parses the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0QszJVIUq0-"
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "\n",
    "example_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dqO_H03VANY"
   },
   "outputs": [],
   "source": [
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9OSa3ZKVOTZ"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0JIegqwlc16"
   },
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Tell me about the various chunking methods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwaU4QSkWY3G"
   },
   "source": [
    "LangChain built-in Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yrf0TtyEWYRc"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"Tell me about the various chunking methods.\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fam7143WpCm"
   },
   "outputs": [],
   "source": [
    "for document in response[\"context\"]:\n",
    "    print(document)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZZVoM5uHw0J"
   },
   "outputs": [],
   "source": [
    "# cleanup\n",
    "vectorstore.delete_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0WCcr_F4-oP"
   },
   "source": [
    "# Assignment 4: Naive RAG\n",
    "\n",
    "In this assignment, you will implement Naive RAG by adjusting various strategies and compare the results.\n",
    "1.   Chunking strategy\n",
    "  *  Chunk size, overlap\n",
    "  *  Token based splitter  \n",
    "2.   Vector indexing\n",
    "3.   Prompt compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJ9aSBdUblAI"
   },
   "source": [
    "## Source document\n",
    "\n",
    "We will use the document that we used in the TA sessuib.\n",
    "\n",
    "*   Source: [RAG Survey Paper](https://arxiv.org/html/2312.10997v5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwenXbzhJD2d"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep abstract, sections from the full HTML.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://arxiv.org/html/2312.10997v5\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"ltx_abstract\", \"ltx_section\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XakayICJRhts"
   },
   "source": [
    "## TODO: Try different chunking options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdK3LTFERoDt"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter1 = RecursiveCharacterTextSplitter(\n",
    "    ###### TODO: Change chunk_size, chunk_overlap ######\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    "    ####################################################\n",
    ")\n",
    "all_splits1 = text_splitter1.split_documents(docs)\n",
    "\n",
    "print(len(all_splits1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbdNFXW_WmMv"
   },
   "source": [
    "## TODO: Try different splitter - split text by tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqJUwU3UWbCp"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet langchain-text-splitters tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSs4IBwjWy1Y"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter2 = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    ########## TODO: Change chunk_size, chunk_overlap ##########\n",
    "    encoding_name=\"cl100k_base\", chunk_size=200, chunk_overlap=0\n",
    "    ############################################################\n",
    ")\n",
    "all_splits2 = text_splitter2.split_documents(docs)\n",
    "\n",
    "print(len(all_splits2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQzoUedBYQwW"
   },
   "source": [
    "## TODO: Try other vector indexing\n",
    "\n",
    "Chroma uses HNSW (Hierarchical Navigable Small World) indexing by default.\n",
    "\n",
    "In order to use other vector indexing, we will use FAISS as a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vRPJFiPjYWBJ"
   },
   "outputs": [],
   "source": [
    "!pip install -qU langchain-community faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFnNJwGlYLwv"
   },
   "outputs": [],
   "source": [
    "embeddings=OpenAIEmbeddings(model='text-embedding-3-small', api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UW_wWl4TZY4R"
   },
   "outputs": [],
   "source": [
    "dimension_size = len(embeddings.embed_query(\"hello world\"))\n",
    "print(dimension_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9hCIHOIbKQl"
   },
   "source": [
    "We will use IndexFlatL2 as the indexing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVjwqHWmZeST"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# create FAISS vector store\n",
    "db = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=faiss.IndexFlatL2(dimension_size),\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHqGWHijbTOg"
   },
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(documents=all_splits1, embedding=embeddings)\n",
    "# db = FAISS.from_documents(documents=all_splits2, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJ31k6AndQnx"
   },
   "outputs": [],
   "source": [
    "retriever2 = db.as_retriever()\n",
    "\n",
    "# test retriever\n",
    "\n",
    "retrieved_docs = retriever2.invoke(\"What are the approaches to the query rewriting?\")\n",
    "\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UosP7HHYcCpd"
   },
   "source": [
    "## TODO: Apply prompt compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2_7vtYucMcT"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever\n",
    "    #base_retriever=retriever2\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"What are the approaches to the query rewriting?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgiOD3k8d7n8"
   },
   "outputs": [],
   "source": [
    "print(compressed_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyKXIZEkk_Q-"
   },
   "source": [
    "## Generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TF4lq4MheAJQ"
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain2 = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    #{\"context\": compression_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Td23yARcljQZ"
   },
   "outputs": [],
   "source": [
    "######## Please try with your own questions ########\n",
    "rag_chain2.invoke(\"Tell me about the various chunking methods.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPinY0u6HRKXqkgvgKIDaK7",
   "provenance": [
    {
     "file_id": "1XZvYCLVn0lC6zP02lDdQS5mgtzhf_JNG",
     "timestamp": 1727014606026
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
