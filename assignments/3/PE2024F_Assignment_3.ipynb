{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0WCcr_F4-oP"
   },
   "source": [
    "# Assignment 3: Tree-of-Thoughts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJ9aSBdUblAI"
   },
   "source": [
    "In this assignment, you will write a program to solve Sudoku using GPT and Tree-of-Thoughts.\n",
    "\n",
    "## What is Sudoku\n",
    "\n",
    "Sudoku is a logic-based puzzle where the goal is to fill a grid so that every row, column, and region contains unique numbers. In this task, we will focus on solving a 4x4 Sudoku using a tree-of-thought approach to systematically explore possible solutions and fill in the grid correctly.\n",
    "\n",
    "![Sudoku Puzzle](https://www.sudokuweb.org/wp-content/uploads/2013/04/sudoku-kids-4x4-10-150x150.png)\n",
    "\n",
    "You can try 4x4 Sudoku game here:\n",
    "* https://www.sudokuweb.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9o8gGNgEx12"
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YD-GUB6s78er"
   },
   "outputs": [],
   "source": [
    "# Install langchain\n",
    "!pip install -qU langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ko0_OeTDlr3"
   },
   "outputs": [],
   "source": [
    "# Install langchain-openai\n",
    "!pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2duN-x-D2tMq"
   },
   "source": [
    "### Set API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3K6uUOvP8DP"
   },
   "outputs": [],
   "source": [
    "# Set API key\n",
    "OPENAI_API_KEY=\"your_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztDA7lWl5Z4s"
   },
   "source": [
    "## Prepare Language Models\n",
    "\n",
    "You can select language models for the thought generation.\n",
    "\n",
    "You can also change the temperature as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Qxvsp02nW5y"
   },
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "low_temperature_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0, api_key=OPENAI_API_KEY, max_tokens=1024)\n",
    "mid_temperature_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5, api_key=OPENAI_API_KEY, max_tokens=1024)\n",
    "high_temperature_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1.0, api_key=OPENAI_API_KEY, max_tokens=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHTtJfl87Ax8"
   },
   "source": [
    "## Using Structured Output in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIRVEitIKg6k"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "\n",
    "structured_llm = mid_temperature_llm.with_structured_output(Joke)\n",
    "\n",
    "joke = structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqSm5hC96G0R"
   },
   "outputs": [],
   "source": [
    "joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svymBL0N6IWx"
   },
   "outputs": [],
   "source": [
    "print(joke.setup)\n",
    "print(joke.punchline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKI5bGmKTfCi"
   },
   "source": [
    "## Test GPT-4o-mini without Tree-of-Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZY52WEGc0Oh"
   },
   "source": [
    "### Define Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6SWflAOrVAi"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WP6aSZf_JegW"
   },
   "outputs": [],
   "source": [
    "solve_prompt = PromptTemplate(\n",
    "    input_variables=[\"game_status\"],\n",
    "    template=\"\"\"\n",
    "    You are a Sudoku solver. Your goal is to solve the 4x4 sudoku puzzle.\n",
    "    The game includes the grid with numbers and empty cells '*'.\n",
    "    Respond in JSON with `answer` key which value is an answer for the puzzle.\n",
    "\n",
    "    Game:\n",
    "    {game_status}\n",
    "\n",
    "    Solve the puzzle.\n",
    "\n",
    "    Output JSON:\n",
    "    {{\n",
    "      'answer': 'answer for the given puzzle'\n",
    "    }}\n",
    "\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtAlIkRY-YWa"
   },
   "source": [
    "### Define Class for the Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9vLgNbm7ScF"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    \"\"\"Answer for the given puzzle\"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"answer for the given puzzle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAbC_0yxEPtI"
   },
   "source": [
    "### Run Answer Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mu_Fk9FB7cri"
   },
   "outputs": [],
   "source": [
    "answer_chain = solve_prompt | mid_temperature_llm.with_structured_output(Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UyF5PGsT7qE6"
   },
   "outputs": [],
   "source": [
    "answer_chain.invoke({\"game_status\": \"[['*', '*', '*', '*'], ['*', '*', 2, '*'], ['*', 1, 3, '*'], [2, 3, '*', 4]]\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMYX759Q3UvX"
   },
   "source": [
    "## TODO: Sudoku Solver with Tree-of-Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXUCCZYREUPg"
   },
   "source": [
    "### Define propose prompt for the next thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rs9qdbM2EcCd"
   },
   "outputs": [],
   "source": [
    "propose_prompt = PromptTemplate(\n",
    "    ##############################\n",
    "    #########    TODO   ##########\n",
    "    ##############################\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JgIDoouEqa2"
   },
   "source": [
    "### Define class for the structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1MJQFMYkQ1-"
   },
   "outputs": [],
   "source": [
    "class Guess(BaseModel):\n",
    "    ##############################\n",
    "    #########    TODO   ##########\n",
    "    ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e07mCs-Rlm2b"
   },
   "outputs": [],
   "source": [
    "propose_chain = propose_prompt | mid_temperature_llm.with_structured_output(Guess) # You can change the llm model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lM-ItaCFTeL"
   },
   "source": [
    "### Util function for extracting proposals from the LLM response\n",
    "\n",
    "You can decide to use it or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WV_J17bGrVJG"
   },
   "outputs": [],
   "source": [
    "def extract_proposals(response):\n",
    "  \"\"\"Extracts proposals from the response of the propose_chain.\"\"\"\n",
    "  try:\n",
    "    return response.next_guesses\n",
    "  except (KeyError, TypeError):\n",
    "    print(\"Failed to extract proposals from response:\", response)\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnLxw2CdrcF5"
   },
   "outputs": [],
   "source": [
    "response = propose_chain.invoke({\"game_status\": \"[['*', '*', '*', '*'], [2, '*', '*', '*'], [4, '*', '*', 3], [3, '*', 4, 2]]\"})\n",
    "extract_proposals(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FnVzeTfJ2Fj"
   },
   "source": [
    "### Check the sudoku is valid or not including blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLiji4URzz4s"
   },
   "outputs": [],
   "source": [
    "def is_valid_sudoku(grid):\n",
    "  \"\"\"Checks if a 4x4 Sudoku grid is valid.\"\"\"\n",
    "\n",
    "  def check_rows(grid):\n",
    "    for row in grid:\n",
    "      if not is_valid_unit(row):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "  def check_cols(grid):\n",
    "    for col_index in range(4):\n",
    "      col = [grid[row_index][col_index] for row_index in range(4)]\n",
    "      if not is_valid_unit(col):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "  def check_subgrids(grid):\n",
    "    for row_start in range(0, 4, 2):\n",
    "      for col_start in range(0, 4, 2):\n",
    "        subgrid = [\n",
    "            grid[row_start][col_start],\n",
    "            grid[row_start][col_start + 1],\n",
    "            grid[row_start + 1][col_start],\n",
    "            grid[row_start + 1][col_start + 1],\n",
    "        ]\n",
    "        if not is_valid_unit(subgrid):\n",
    "          return False\n",
    "    return True\n",
    "\n",
    "  def is_valid_unit(unit):\n",
    "    digits = [digit for digit in unit if digit != '*']\n",
    "    return len(set(digits)) == len(digits)\n",
    "\n",
    "  return check_rows(grid) and check_cols(grid) and check_subgrids(grid)\n",
    "\n",
    "# Example usage:\n",
    "sudoku_grid = [\n",
    "    ['*', '*', '*', '*'],\n",
    "    ['2', '*', '*', '*'],\n",
    "    ['4', '*', '*', '3'],\n",
    "    ['3', '*', '4', '2']\n",
    "]\n",
    "\n",
    "if is_valid_sudoku(sudoku_grid):\n",
    "  print(\"The Sudoku grid is valid.\")\n",
    "else:\n",
    "  print(\"The Sudoku grid is not valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK0NhC5kFj7I"
   },
   "source": [
    "### Rule-based evaluation function for the guess\n",
    "\n",
    "Gives higher score when the blanks are filled compared to the original game status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJReLdLHzft0"
   },
   "outputs": [],
   "source": [
    "def rule_based_evaluation(initial_game, guess):\n",
    "  \"\"\"Calculate evaluation score from the guess.\"\"\"\n",
    "  blank_count_game = sum(row.count('*') for row in initial_game)\n",
    "  blank_count_guess = sum(row.count('*') for row in guess)\n",
    "  if is_valid_sudoku(guess):\n",
    "    return (blank_count_game - blank_count_guess) / 16.0\n",
    "  else:\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_P6jZAN11qV"
   },
   "outputs": [],
   "source": [
    "sudoku_grid1 = [\n",
    "    ['*', '*', '*', '*'],\n",
    "    ['2', '*', '*', '*'],\n",
    "    ['4', '*', '*', '3'],\n",
    "    ['3', '*', '4', '2']\n",
    "]\n",
    "sudoku_grid2 = [\n",
    "    ['1', '*', '*', '*'],\n",
    "    ['2', '*', '*', '*'],\n",
    "    ['4', '*', '*', '3'],\n",
    "    ['3', '1', '4', '2']\n",
    "]\n",
    "\n",
    "rule_based_evaluation(sudoku_grid1, sudoku_grid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXiqAMEvKKj1"
   },
   "source": [
    "### Run Tree-of-Thought Sudoku solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ad36EPtLsDHT"
   },
   "outputs": [],
   "source": [
    "LOOPS = 10\n",
    "PROPOSAL_RUNS_PER_STATE = 1  # Adjust as needed\n",
    "EVAL_RUNS_PER_STATE = 1  # Adjust as needed\n",
    "BRANCH_FACTOR = 1 # 1: Greedy, Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPp-DyNFrsFt"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def solve_sudoku_tot(sudoku_grid):\n",
    "  \"\"\"Solves a 4x4 Sudoku puzzle using a tree-search approach with LLMs.\n",
    "\n",
    "  Args:\n",
    "    sudoku_grid: A list of lists representing the initial Sudoku grid.\n",
    "                  Empty cells are represented by '*'.\n",
    "\n",
    "  Returns:\n",
    "    A list of lists representing the solved Sudoku grid, or None if no solution is found.\n",
    "  \"\"\"\n",
    "  initial_game = sudoku_grid\n",
    "  curr_states = [sudoku_grid] # Stores current guess for generating next thoughts\n",
    "  proposal_and_score = []\n",
    "\n",
    "  for loop in range(LOOPS):\n",
    "    print('Curr states:', curr_states)\n",
    "    for state in curr_states:\n",
    "      proposal_and_score = proposal_and_score[1:] # popup the first element (state with best score)\n",
    "      proposals = []\n",
    "      for _ in range(PROPOSAL_RUNS_PER_STATE): # runs PROPOSAL_RUNS_PER_STATE times\n",
    "        # generate proposals based on the current intermediate guess\n",
    "        proposals.extend(extract_proposals(propose_chain.invoke({\"game_status\": str(state)})))\n",
    "        print(\"current proposals:\", proposals)\n",
    "\n",
    "      for proposal in proposals:\n",
    "        # for each generated proposals, evaluate score\n",
    "        score = 0\n",
    "        for _ in range(EVAL_RUNS_PER_STATE): # get score multiple times to get average, but runs one time for rule-based evaluation\n",
    "          try:\n",
    "            score += rule_based_evaluation(initial_game, ast.literal_eval(proposal))\n",
    "          except:\n",
    "            score += 0\n",
    "\n",
    "        proposal_and_score.append((proposal, score/EVAL_RUNS_PER_STATE))\n",
    "        print(\"current proposal_and_score: \", proposal_and_score)\n",
    "\n",
    "\n",
    "    proposal_and_score.sort(key=lambda x: x[1], reverse=True) # sort the proposals by the score\n",
    "    curr_states = [item[0] for item in proposal_and_score[:BRANCH_FACTOR]]\n",
    "    if '*' not in str(curr_states[0]): # if the proposal is the final proposal without any blank\n",
    "      print('Solved! The answer is: ', str(curr_states[0]))\n",
    "      return ast.literal_eval(curr_states[0]), True, loop # outputs answer, isSolved, number of loops\n",
    "    else:\n",
    "      continue # continue loop on the new current state\n",
    "  print('Cannot solve this puzzle')\n",
    "  return ast.literal_eval(curr_states[0]), False, loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFabrwUis1E_"
   },
   "outputs": [],
   "source": [
    "solve_sudoku_tot(\"[[2, 3, '*', 4], ['*', 1, 3, '*'], ['*', '*', 2, '*'], ['*', '*', '*', '*']]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MABzgOXa_wEC"
   },
   "outputs": [],
   "source": [
    "sudoku_puzzle_test = [\n",
    "    \"[[3, 4, '*', '*'], [1, '*', '*', '*'], ['*', '*', 2, 1], [2, '*', '*', '*']]\",\n",
    "    \"[[3, '*', '*', 2], ['*', 1, 4, 3], ['*', 2, 3, 1], [1, '*', 2, 4]]\",\n",
    "    \"[['*', '*', '*', 4], ['*', 1, '*', '*'], ['*', '*', '*', 3], ['*', 4, 2, 1]]\",\n",
    "    \"[[1, '*', 2, '*'], [2, '*', '*', 3], [3, '*', 4, 2], [4, '*', 3, '*']]\",\n",
    "    \"[['*', '*', '*', 4], ['*', 2, '*', '*'], [3, 4, 1, '*'], [2, 1, '*', '*']]\",\n",
    "    \"[[2, '*', '*', 4], [1, 4, '*', 3], [3, 1, '*', '*'], ['*', 2, 3, 1]]\",\n",
    "    \"[[2, '*', 3, '*'], [3, '*', 2, 1], [1, '*', '*', 2], [4, '*', '*', '*']]\",\n",
    "    \"[['*', '*', 1, 3], [1, '*', '*', '*'], ['*', '*', '*', 1], [3, 1, '*', 4]]\",\n",
    "    \"[['*', '*', '*', 4], [1, 4, 2, 3], [3, 1, 4, '*'], [4, 2, '*', '*']]\",\n",
    "    \"[['*', 1, 2, 4], [2, '*', 1, '*'], ['*', '*', 3, '*'], ['*', 3, '*', '*']]\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAiyD6F3JEbN"
   },
   "outputs": [],
   "source": [
    "# get solve ratio for the test puzzle set\n",
    "\n",
    "solve_count = 0\n",
    "total_count = len(sudoku_puzzle_test)\n",
    "total_loops = 0\n",
    "\n",
    "for puzzle in sudoku_puzzle_test:\n",
    "  answer, solved, loops = solve_sudoku_tot(puzzle)\n",
    "  if solved:\n",
    "    if is_valid_sudoku(answer):\n",
    "      solve_count += 1\n",
    "      total_loops += loops\n",
    "\n",
    "solve_ratio = solve_count / total_count if total_count > 0 else 0\n",
    "average_loops = total_loops / solve_count if solve_count > 0 else 0\n",
    "print(f\"Solve ratio for the test puzzle set: {solve_ratio}\")\n",
    "print(f\"Average loops for solving: {average_loops}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUckmBbeDAjUl1gW/pldH7",
   "provenance": [
    {
     "file_id": "1XZvYCLVn0lC6zP02lDdQS5mgtzhf_JNG",
     "timestamp": 1727014606026
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
