{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0WCcr_F4-oP"
   },
   "source": [
    "# Topic 3: Tree-of-Thoughts, Graph-of-Thoughts, and Self-Ask\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "* Check the codes and prompts of ToT, GoT, and Self-Ask\n",
    "* How the prompts work on various tasks.\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "1. **Tree-of-Thoughts**\n",
    "2. **Graph-of-Thoughts**\n",
    "3. **Self-Ask**\n",
    "\n",
    "**Paper Links:**\n",
    "\n",
    "1. **Tree-of-Thoughts**: [Link](https://arxiv.org/abs/2305.10601)\n",
    "2. **Graph-of-Thoughts**: [Link](https://arxiv.org/abs/2308.09687)\n",
    "3. **Self-Ask**: [Link](https://arxiv.org/abs/2210.03350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9o8gGNgEx12"
   },
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPYTNLM2HvZO"
   },
   "outputs": [],
   "source": [
    "# Install openai\n",
    "!pip install -qU openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YD-GUB6s78er"
   },
   "outputs": [],
   "source": [
    "# Install langchain\n",
    "!pip install -qU langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ko0_OeTDlr3"
   },
   "outputs": [],
   "source": [
    "# Install langchain-openai\n",
    "!pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2duN-x-D2tMq"
   },
   "source": [
    "**Set API key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3K6uUOvP8DP"
   },
   "outputs": [],
   "source": [
    "# Set API key\n",
    "OPENAI_API_KEY=\"your_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOFruKHs76Az"
   },
   "source": [
    "## 1. Tree-of-Thoughts\n",
    "\n",
    "We will test prompts with simplified version of Tree-of-Thoughts code.\n",
    "\n",
    "Original code source: [Link](https://github.com/princeton-nlp/tree-of-thought-llm)\n",
    "\n",
    "Simplified code source: [Link](https://github.com/ayushtues/tot_from_scratch/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztDA7lWl5Z4s"
   },
   "source": [
    "### Using Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Qxvsp02nW5y"
   },
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7, api_key=OPENAI_API_KEY,  max_tokens=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CA2e7_09rK7r"
   },
   "source": [
    "### Define Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJ7Po7odoPZ7"
   },
   "outputs": [],
   "source": [
    "# Import simple output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-V5HJxYrQbi"
   },
   "source": [
    "### Define Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6SWflAOrVAi"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFwaRjNQqoBV"
   },
   "outputs": [],
   "source": [
    "propose_prompt = PromptTemplate(\n",
    "    input_variables=[\"state\"],\n",
    "    template=\"\"\"\n",
    "    Your goal is to use the given numbers and the basic arithmetic operations (+, -, *, /) to obtain the number 24.\n",
    "    You can use each number only once, but you can use the operations in any order and as many times as you want.\n",
    "    This task will take multiple steps. For the current step, you choose two numbers and perform an arithmetic operation on them.\n",
    "\n",
    "    Examples\n",
    "    Input: 2 8 8 14\n",
    "    Possible next steps:\n",
    "    Output1: 2 + 8 = 10 (left: 8 10 14)\n",
    "    Output2: 8 / 2 = 4 (left: 4 8 14)\n",
    "    Output3: 14 + 2 = 16 (left: 8 8 16)\n",
    "    Output4: 2 * 8 = 16 (left: 8 14 16)\n",
    "\n",
    "    Input: 4 10 12 1\n",
    "    Possible next steps:\n",
    "    Output1: 12 - 10 = 2 (left: 4 2 1)\n",
    "    Output2: 4 * 10 = 40 (left: 40 12 1)\n",
    "    Output3: 12 + 1 = 13 (left: 4 10 13)\n",
    "    Output4 12/4 = 3 (left: 3 10 1)\n",
    "\n",
    "    Now for the below input\n",
    "    Input: {state}\n",
    "    Possible next steps:\"\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SSnxakHr5zd"
   },
   "outputs": [],
   "source": [
    "eval_prompt = PromptTemplate(\n",
    "    input_variables=[\"proposal\"],\n",
    "    template=\"\"\"\n",
    "    Evaluate if given numbers can reach 24 using basic arithmetic operations (+, -, *, /).\n",
    "    You must use each number only once, but you can use the operations in any order and as many times as you want.\n",
    "\n",
    "    Some examples are:\n",
    "    Input: 10, 14 -> 10 + 14 = 24. -> Output: \"sure\"\n",
    "    Input: 4, 9, 10, 13 -> (10 - 4) * (13 - 9) = 24. -> Output: \"sure\"\n",
    "    Input: 20, 10: Not possible -> Output: \"impossible\"\n",
    "\n",
    "    Can the numbers {proposal} reach 24?\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_lZpTATuaku"
   },
   "outputs": [],
   "source": [
    "# Example usage of propose_prompt\n",
    "state = \"2 8 8 14\"\n",
    "\n",
    "propose_chain = propose_prompt | llm | parser\n",
    "\n",
    "proposal = propose_chain.invoke({\"state\": state})\n",
    "print(proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQgmrhp_uK5U"
   },
   "outputs": [],
   "source": [
    "def extract_proposals(text):\n",
    "    text = text.split(\"\\n\")\n",
    "\n",
    "    text = [item for item in text if \"Output\" in item]\n",
    "\n",
    "    proposals = []\n",
    "    for x in text:\n",
    "        x = x.lower()\n",
    "        x = x.split(\"left:\")\n",
    "        if len(x) == 2 :\n",
    "            x = x[1].split(')')[0]\n",
    "            proposals.append(x)\n",
    "    return proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xRtM-9nvFfV"
   },
   "outputs": [],
   "source": [
    "proposals = extract_proposals(proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3k6DOh1VvUKg"
   },
   "outputs": [],
   "source": [
    "proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFt4AHhJ4ReG"
   },
   "outputs": [],
   "source": [
    "# Example usage of propose_prompt\n",
    "proposal = \"2, 8, 6\"\n",
    "\n",
    "eval_chain = eval_prompt | llm | parser\n",
    "\n",
    "eval = eval_chain.invoke({\"proposal\": proposal})\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9puADZ14MQl"
   },
   "outputs": [],
   "source": [
    "def extract_evaluation(text):\n",
    "    text  = text.lower()\n",
    "    if \"impossible\" in text:\n",
    "        return 0\n",
    "    elif \"sure\" in text:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IuYVgHSd5PNB"
   },
   "outputs": [],
   "source": [
    "extract_evaluation(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyoJv6FQhsv7"
   },
   "source": [
    "### Run Tree-of-Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkZCXSl75aFq"
   },
   "outputs": [],
   "source": [
    "curr_states = [\"6 7 9 9\"]\n",
    "\n",
    "TREE_DEPTH = 3\n",
    "PROPOSAL_RUNS_PER_STATE = 2\n",
    "EVAL_RUNS_PER_STATE = 1\n",
    "BRANCH_FACTOR = 2\n",
    "\n",
    "for depth in range(TREE_DEPTH):\n",
    "    proposal_and_score = []\n",
    "    for state in curr_states:\n",
    "        proposals = []\n",
    "        for _ in range(PROPOSAL_RUNS_PER_STATE):\n",
    "            proposals += extract_proposals(propose_chain.invoke({\"state\": state}))\n",
    "            print(\"current proposals:\", proposals)\n",
    "\n",
    "        for proposal in proposals:\n",
    "            score = 0\n",
    "            for _ in range(EVAL_RUNS_PER_STATE):\n",
    "                score += extract_evaluation(eval_chain.invoke({\"proposal\": proposal}))\n",
    "\n",
    "            proposal_and_score.append((proposal, score/EVAL_RUNS_PER_STATE))\n",
    "            print(\"current proposal_and_score: \", proposal_and_score)\n",
    "\n",
    "    # sort proposals by score\n",
    "    proposal_and_score.sort(key=lambda x: x[1], reverse=True)\n",
    "    curr_states = [item[0] for item in proposal_and_score[:BRANCH_FACTOR]]\n",
    "\n",
    "print(curr_states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MAdbQUYYrJ2"
   },
   "source": [
    "## 2. Graph-of-Thoughts\n",
    "\n",
    "We will test prompts with simplified version of Graph-of-Thoughts.\n",
    "Please check the GoT github repo for the original code.\n",
    "\n",
    "Original code source:\n",
    "[Link](https://github.com/spcl/graph-of-thoughts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvb5vsugPSwT"
   },
   "source": [
    "### Define Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ttz_ce8QYMq7"
   },
   "outputs": [],
   "source": [
    "split_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"\"\"\n",
    "<Instruction> Split the following list of 32 numbers into 2 lists of 16 numbers each, the first list should contain the first 16 numbers and the second list the second 16 numbers.\n",
    "Only output the final 2 lists in the following format without any additional text or thoughts!:\n",
    "    \"List 1\": [3, 4, 3, 5, 7, 8, 1, ...]\n",
    "    \"List 2\": [2, 9, 2, 4, 7, 1, 5, ...]\n",
    "</Instruction>\n",
    "\n",
    "<Example>\n",
    "Input: [9, 6, 7, 7, 2, 0, 2, 2, 3, 5, 0, 9, 2, 2, 4, 4, 5, 2, 5, 1, 2, 8, 3, 8, 3, 9, 6, 0, 4, 2, 2, 3]\n",
    "Output:\n",
    "    \"List 1\": [9, 6, 7, 7, 2, 0, 2, 2, 3, 5, 0, 9, 2, 2, 4, 4]\n",
    "    \"List 2\": [5, 2, 5, 1, 2, 8, 3, 8, 3, 9, 6, 0, 4, 2, 2, 3]\n",
    "\n",
    "</Example>\n",
    "\n",
    "Input: {input}\n",
    "Output: \"\"\"\n",
    ")\n",
    "\n",
    "sort_prompt =  PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"\"\"\n",
    "<Instruction> Sort the following list of numbers in ascending order. Output only the sorted list of numbers, no additional text. </Instruction>\n",
    "\n",
    "<Examples>\n",
    "Input: [5, 1, 0, 1, 2, 0, 4, 8, 1, 9, 5, 1, 3, 3, 9, 7]\n",
    "Output: [0, 0, 1, 1, 1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 9, 9]\n",
    "\n",
    "Input: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9, 4, 3, 5, 6, 6, 4, 4, 5, 2, 0, 9, 3, 3, 9, 2, 1]\n",
    "Output: [0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 9]\n",
    "\n",
    "Input: [4, 4, 9, 7, 9, 7, 0, 0, 4, 9, 1, 7, 9, 5, 8, 7, 5, 6, 3, 8, 6, 7, 5, 8, 5, 0, 6, 3, 7, 0, 5, 3, 7, 5, 2, 4, 4, 9, 0, 7, 8, 2, 7, 7, 7, 2, 1, 3, 9, 9, 7, 9, 6, 6, 4, 5, 4, 2, 0, 8, 9, 0, 2, 2]\n",
    "Output: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "</Examples>\n",
    "\n",
    "Input: {input}\n",
    "Output: \"\"\"\n",
    ")\n",
    "\n",
    "merge_prompt = PromptTemplate(\n",
    "    input_variables=[\"input1\", \"input2\", \"length1\", \"length2\"],\n",
    "    template=\"\"\"\n",
    "<Instruction> Merge the following 2 sorted lists of length {length1} each, into one sorted list of length {length2} using a merge sort style approach.\n",
    "Only output the final merged list without any additional text or thoughts!:</Instruction>\n",
    "\n",
    "<Approach>\n",
    "To merge the two lists in a merge-sort style approach, follow these steps:\n",
    "1. Compare the first element of both lists.\n",
    "2. Append the smaller element to the merged list and move to the next element in the list from which the smaller element came.\n",
    "3. Repeat steps 1 and 2 until one of the lists is empty.\n",
    "4. Append the remaining elements of the non-empty list to the merged list.\n",
    "</Approach>\n",
    "\n",
    "Merge the following two lists into one sorted list:\n",
    "1: {input1}\n",
    "2: {input2}\n",
    "\n",
    "Merged list: \"\"\"\n",
    ")\n",
    "\n",
    "value_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"variant\"],\n",
    "    template=\"\"\"\n",
    "<Instruction> The following two lists represent an input list of numbers and a variant of that list. Evaluate if the variant is correctly sorted, with respect to the input list.\n",
    "Answer 1 if the variant list is correctly sorted, deduct 0.1 for the each errors in the variant.\n",
    "Only output the value without any additional text or thoughts!:</Instruction>\n",
    "\n",
    "<Approach>\n",
    "To score the variant list follow these steps:\n",
    "1. For each number from 0 to 9, compare the frequency of that number in the variant list to the frequency of that number in the input list.\n",
    "2. Iterate through the variant list and add or remove numbers as needed to make the frequency of each number in the variant list match the frequency of that number in the input list.\n",
    "3. Count the number of errors in the variant list and deduct from 1.\n",
    "</Approach>\n",
    "\n",
    "<Examples>\n",
    "Input: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9]\n",
    "Variant: [0, 0, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 7, 7, 8, 8, 9, 9, 9, 9]\n",
    "Reason: The variant list contains four extra 0s, two extra 4s and three extra 9s and is missing two 2s.\n",
    "Output: 0\n",
    "\n",
    "Input: [6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9, 2, 4, 9, 0, 7, 6, 5, 6, 6, 2, 8, 3, 9, 5, 6, 1]\n",
    "Variant: [0, 1, 1, 2, 2, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9]\n",
    "Reason: The variant list contains two extra 4s and is missing two 6s and one 9.\n",
    "Output: 0.5\n",
    "\n",
    "Input: [4, 4, 9, 7, 9, 7, 0, 0, 4, 9, 1, 7, 9, 5, 8, 7, 5, 6, 3, 8, 6, 7, 5, 8, 5, 0, 6, 3, 7, 0, 5, 3, 7, 5, 2, 4, 4, 9, 0, 7, 8, 2, 7, 7, 7, 2, 1, 3, 9, 9, 7, 9, 6, 6, 4, 5, 4, 2, 0, 8, 9, 0, 2, 2]\n",
    "Incorrectly Sorted: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "Reason: The variant list contains one extra 8 and is missing two 2s, one 3, three 4s, two 5s, one 6, six 7s and one 9.\n",
    "Output: 0\n",
    "</Examples>\n",
    "\n",
    "Input: {input}\n",
    "Variant: {variant}\n",
    "\n",
    "Merged list: \"\"\"\n",
    ")\n",
    "\n",
    "improve_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\",\"incorrectly_sorted\",\"length\"],\n",
    "    template=\"\"\"\n",
    "<Instruction> The following two lists represent an unsorted list of numbers and a sorted variant of that list. The sorted variant is not correct. Fix the sorted variant so that it is correct.\n",
    "Make sure that the output list is sorted in ascending order, has the same number of elements as the input list ({length}), and contains the same elements as the input list. </Instruction>\n",
    "\n",
    "<Approach>\n",
    "To fix the incorrectly sorted list follow these steps:\n",
    "1. For each number from 0 to 9, compare the frequency of that number in the incorrectly sorted list to the frequency of that number in the input list.\n",
    "2. Iterate through the incorrectly sorted list and add or remove numbers as needed to make the frequency of each number in the incorrectly sorted list match the frequency of that number in the input list.\n",
    "</Approach>\n",
    "\n",
    "<Examples>\n",
    "Input: [3, 7, 0, 2, 8, 1, 2, 2, 2, 4, 7, 8, 5, 5, 3, 9]\n",
    "Incorrectly Sorted: [0, 0, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 7, 7, 8, 8, 9, 9, 9, 9]\n",
    "Reason: The incorrectly sorted list contains four extra 0s, two extra 4s and three extra 9s and is missing two 2s.\n",
    "Output: [0, 1, 2, 2, 2, 2, 3, 3, 4, 5, 5, 7, 7, 8, 8, 9]\n",
    "\n",
    "Input: [6, 4, 5, 7, 5, 6, 9, 7, 6, 9, 4, 6, 9, 8, 1, 9, 2, 4, 9, 0, 7, 6, 5, 6, 6, 2, 8, 3, 9, 5, 6, 1]\n",
    "Incorrectly Sorted: [0, 1, 1, 2, 2, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9]\n",
    "Reason: The incorrectly sorted list contains two extra 4s and is missing two 6s and one 9.\n",
    "Output: [0, 1, 1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 9, 9, 9, 9, 9, 9]\n",
    "\n",
    "Input: [4, 4, 9, 7, 9, 7, 0, 0, 4, 9, 1, 7, 9, 5, 8, 7, 5, 6, 3, 8, 6, 7, 5, 8, 5, 0, 6, 3, 7, 0, 5, 3, 7, 5, 2, 4, 4, 9, 0, 7, 8, 2, 7, 7, 7, 2, 1, 3, 9, 9, 7, 9, 6, 6, 4, 5, 4, 2, 0, 8, 9, 0, 2, 2]\n",
    "Incorrectly Sorted: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "Reason: The incorrectly sorted list contains one extra 8 and is missing two 2s, one 3, three 4s, two 5s, one 6, six 7s and one 9.\n",
    "Output: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "</Examples>\n",
    "\n",
    "Input: {input}\n",
    "Incorrectly Sorted: {incorrectly_sorted}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nl03vbQPJKSY"
   },
   "source": [
    "### Create random 32 numbers list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sCYqAwQHLwI"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_random_list(length, min_val, max_val):\n",
    "  \"\"\"Creates a list of random integers within a specified range.\n",
    "\n",
    "  Args:\n",
    "    length: The desired length of the list.\n",
    "    min_val: The minimum value for the random integers.\n",
    "    max_val: The maximum value for the random integers.\n",
    "\n",
    "  Returns:\n",
    "    A list of random integers.\n",
    "  \"\"\"\n",
    "  return [random.randint(min_val, max_val) for _ in range(length)]\n",
    "\n",
    "random_list = create_random_list(32, 0, 9)\n",
    "print(random_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghO2Y5UTXayY"
   },
   "source": [
    "### Split to two lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xjinK8oYI9G"
   },
   "outputs": [],
   "source": [
    "split_chain = split_prompt | llm | parser\n",
    "split_result = split_chain.invoke({\"input\": str(random_list)})\n",
    "print(split_result)\n",
    "\n",
    "def extract_lists(text):\n",
    "    text = text.lower()\n",
    "    text = text.split(\"\\n\")\n",
    "\n",
    "    text = [item for item in text if \"list\" in item]\n",
    "\n",
    "    lists = []\n",
    "    for x in text:\n",
    "        x = x.split(\":\")\n",
    "        if len(x) == 2 :\n",
    "            x = x[1]\n",
    "            lists.append(x)\n",
    "    return lists\n",
    "\n",
    "list1_str, list2_str = extract_lists(split_result)[0], extract_lists(split_result)[1]\n",
    "\n",
    "print(list1_str,list2_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkoxR2yJXvvJ"
   },
   "source": [
    "### Sort each list and repeat two times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlvDYdSvYRcF"
   },
   "outputs": [],
   "source": [
    "sort_chain = sort_prompt | llm | parser\n",
    "sort_result1_1 = sort_chain.invoke({\"input\": list1_str})\n",
    "sort_result1_2 = sort_chain.invoke({\"input\": list1_str})\n",
    "sort_result2_1 = sort_chain.invoke({\"input\": list2_str})\n",
    "sort_result2_2 = sort_chain.invoke({\"input\": list2_str})\n",
    "\n",
    "print(sort_result1_1, sort_result1_2, sort_result2_1, sort_result2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SXG2HYedwK1"
   },
   "source": [
    "### Merge two lists into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pQhc92IZByC"
   },
   "outputs": [],
   "source": [
    "merge_chain = merge_prompt | llm | parser\n",
    "merge_result1 = merge_chain.invoke({\"input1\": sort_result1_1, \"input2\": sort_result2_1, \"length1\": 16, \"length2\": 32})\n",
    "merge_result2 = merge_chain.invoke({\"input1\": sort_result1_2, \"input2\": sort_result2_1, \"length1\": 16, \"length2\": 32})\n",
    "merge_result3 = merge_chain.invoke({\"input1\": sort_result1_1, \"input2\": sort_result2_2, \"length1\": 16, \"length2\": 32})\n",
    "merge_result4 = merge_chain.invoke({\"input1\": sort_result1_2, \"input2\": sort_result2_2, \"length1\": 16, \"length2\": 32})\n",
    "print(merge_result1, merge_result2, merge_result3, merge_result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_HhgPlbd0xX"
   },
   "source": [
    "### Value each merge result and keep one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-t-TGZ4dYs6"
   },
   "outputs": [],
   "source": [
    "value_chain = value_prompt | llm | parser\n",
    "value_result1 = value_chain.invoke({\"input\": random_list, \"variant\": merge_result1})\n",
    "value_result2 = value_chain.invoke({\"input\": random_list, \"variant\": merge_result2})\n",
    "value_result3 = value_chain.invoke({\"input\": random_list, \"variant\": merge_result3})\n",
    "value_result4 = value_chain.invoke({\"input\": random_list, \"variant\": merge_result4})\n",
    "print(value_result1, value_result2, value_result3, value_result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xo47gKgvdvJ3"
   },
   "outputs": [],
   "source": [
    "value_results = [\n",
    "    (merge_result1, float(value_result1)),\n",
    "    (merge_result2, float(value_result2)),\n",
    "    (merge_result3, float(value_result3)),\n",
    "    (merge_result4, float(value_result4))\n",
    "]\n",
    "\n",
    "# Sort the results by the value in descending order\n",
    "value_results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select the merge result with the highest value\n",
    "best_merge_result = value_results[0][0]\n",
    "\n",
    "print(\"Best Merge Result:\", best_merge_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZTHlV7DeYxO"
   },
   "source": [
    "### Refine the best thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFi2nNBDecZI"
   },
   "outputs": [],
   "source": [
    "refine_chain= improve_prompt | llm | parser\n",
    "refine_result1 = refine_chain.invoke({\"input\": random_list, \"incorrectly_sorted\": best_merge_result, \"length\": 32})\n",
    "refine_result2 = refine_chain.invoke({\"input\": random_list, \"incorrectly_sorted\": best_merge_result, \"length\": 32})\n",
    "print(\"Refine result 1: \", refine_result1,\"\\n\\n\\nRefine result 2: \", refine_result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36hs17gmet1P"
   },
   "source": [
    "### Compare with the correctly sorted list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDgiZToUeyyM"
   },
   "outputs": [],
   "source": [
    "sorted_list = sorted(random_list)\n",
    "print(sorted_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m404atfS7Y4q"
   },
   "source": [
    "## 3. Self-Ask\n",
    "\n",
    "Code source: [Link](https://github.com/ofirpress/self-ask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeuWhys7PWqV"
   },
   "source": [
    "### Test Search Engine\n",
    "\n",
    "We will use duckduckgo for the search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2hTqdNVBpQE"
   },
   "outputs": [],
   "source": [
    "!pip install -qU duckduckgo_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnKa4KZyKo-U"
   },
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# Example usage:\n",
    "query = \"What is the capital of France?\"\n",
    "results = DDGS().text(query, max_results=1)\n",
    "\n",
    "for result in results:\n",
    "  print(result['title'])\n",
    "  print(result['body'])\n",
    "  print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMXwcu_CPhBr"
   },
   "source": [
    "### Define prompt with 4 few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEvWstRe_WPW"
   },
   "outputs": [],
   "source": [
    "self_ask_prompt = ['''Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: How old was Muhammad Ali when he died?\n",
    "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
    "Follow up: How old was Alan Turing when he died?\n",
    "Intermediate answer: Alan Turing was 41 years old when he died.\n",
    "So the final answer is: Muhammad Ali\n",
    "\n",
    "Question: When was the founder of craigslist born?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the founder of craigslist?\n",
    "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
    "Follow up: When was Craig Newmark born?\n",
    "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
    "So the final answer is: December 6, 1952\n",
    "\n",
    "Question: Who was the maternal grandfather of George Washington?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the mother of George Washington?\n",
    "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
    "Follow up: Who was the father of Mary Ball Washington?\n",
    "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
    "So the final answer is: Joseph Ball\n",
    "\n",
    "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who is the director of Jaws?\n",
    "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
    "Follow up: Where is Steven Spielberg from?\n",
    "Intermediate Answer: The United States.\n",
    "Follow up: Who is the director of Casino Royale?\n",
    "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
    "Follow up: Where is Martin Campbell from?\n",
    "Intermediate Answer: New Zealand.\n",
    "So the final answer is: No\n",
    "\n",
    "Question: ''',\n",
    "'''\n",
    "Are follow up questions needed here:''']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6fLf-I2H3F3"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TXA-HwXPr-K"
   },
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnGeAseP_iJL"
   },
   "outputs": [],
   "source": [
    "def promptf(question, prompt, intermediate = \"\\nIntermediate answer:\", followup = \"Follow up:\", finalans= '\\nSo the final answer is:'):\n",
    "    cur_prompt = prompt[0] +  question + prompt[1]\n",
    "\n",
    "    print(cur_prompt, end ='')\n",
    "\n",
    "    ret_text = call_gpt(cur_prompt, intermediate)\n",
    "\n",
    "    while followup in get_last_line(ret_text):\n",
    "\n",
    "\n",
    "      cur_prompt += ret_text\n",
    "      question = extract_question(ret_text)\n",
    "      external_answer = get_answer(question)\n",
    "\n",
    "      if external_answer is not None:\n",
    "        cur_prompt += intermediate + ' ' + external_answer + '.'\n",
    "        print(intermediate + ' ' + yellowfy(external_answer) + '.', end='' )\n",
    "        ret_text = call_gpt(cur_prompt, intermediate)\n",
    "      else:\n",
    "        #We only get here in the very rare case that search engine returns no answer.\n",
    "        cur_prompt += intermediate\n",
    "        print(intermediate + ' ')\n",
    "        gpt_answer = call_gpt(cur_prompt, ['\\n'+followup, finalans])\n",
    "        cur_prompt += gpt_answer\n",
    "\n",
    "\n",
    "    if finalans not in ret_text:\n",
    "      cur_prompt += finalans\n",
    "      print(finalans, end = '')\n",
    "      ret_text = call_gpt(cur_prompt, '\\n')\n",
    "\n",
    "    return cur_prompt + ret_text\n",
    "\n",
    "def get_answer(question):\n",
    "  results = DDGS().text(question, max_results=1)\n",
    "  return results[0]['body']\n",
    "\n",
    "def call_gpt(cur_prompt, stop):\n",
    "  completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": cur_prompt\n",
    "      }\n",
    "    ],\n",
    "    max_tokens=256,\n",
    "    temperature=0.0,\n",
    "    stop=stop\n",
    "  )\n",
    "\n",
    "  returned = completion.choices[0].message.content\n",
    "  print(greenify(returned), end='')\n",
    "  return returned\n",
    "\n",
    "\n",
    "def extract_answer(generated):\n",
    "    if '\\n' not in generated:\n",
    "        last_line =  generated\n",
    "    else:\n",
    "        last_line = generated.split('\\n')[-1]\n",
    "\n",
    "    if ':' not in last_line:\n",
    "        after_colon = last_line\n",
    "    else:\n",
    "        after_colon = generated.split(':')[-1]\n",
    "\n",
    "    if ' ' == after_colon[0]:\n",
    "        after_colon = after_colon[1:]\n",
    "    if '.' == after_colon[-1]:\n",
    "        after_colon = after_colon[:-1]\n",
    "\n",
    "    return after_colon\n",
    "\n",
    "def extract_question(generated):\n",
    "    if '\\n' not in generated:\n",
    "        last_line =  generated\n",
    "    else:\n",
    "        last_line = generated.split('\\n')[-1]\n",
    "\n",
    "    if 'Follow up:' not in last_line:\n",
    "      print('we probably should never get here...' + generated)\n",
    "\n",
    "    if ':' not in last_line:\n",
    "        after_colon = last_line\n",
    "    else:\n",
    "        after_colon = generated.split(':')[-1]\n",
    "\n",
    "    if ' ' == after_colon[0]:\n",
    "        after_colon = after_colon[1:]\n",
    "    if '?' != after_colon[-1]:\n",
    "        print('we probably should never get here...' + generated)\n",
    "\n",
    "    return after_colon\n",
    "\n",
    "def get_last_line(generated):\n",
    "    if '\\n' not in generated:\n",
    "        last_line =  generated\n",
    "    else:\n",
    "        last_line = generated.split('\\n')[-1]\n",
    "\n",
    "\n",
    "    return last_line\n",
    "\n",
    "def greenify(input):\n",
    "  return \"\\x1b[102m\" + input + \"\\x1b[0m\"\n",
    "\n",
    "def yellowfy(input):\n",
    "  return \"\\x1b[106m\" + input + \"\\x1b[0m\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRRVHnJUPvsn"
   },
   "source": [
    "### Test Self-Ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjAmcqRcLLWC"
   },
   "outputs": [],
   "source": [
    "question = \"What is the hometown of the reigning men's U.S. Open champion?\"\n",
    "\n",
    "ret = promptf(question, self_ask_prompt)\n",
    "clean_ans = extract_answer(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2XO8DgcM7bB"
   },
   "outputs": [],
   "source": [
    "question = \"Who was president of U.S. when semiconductor was discovered?\"\n",
    "\n",
    "ret = promptf(question, self_ask_prompt)\n",
    "clean_ans = extract_answer(ret)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO6xzEbzBVCVoSzsOaDpstr",
   "provenance": [
    {
     "file_id": "1Vk_m6Z-8AOVIBYj-C08UyttGMeyZWiEH",
     "timestamp": 1728917435574
    },
    {
     "file_id": "1XZvYCLVn0lC6zP02lDdQS5mgtzhf_JNG",
     "timestamp": 1727014606026
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
